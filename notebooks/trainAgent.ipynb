{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\grid2op\\Backend\\pandaPowerBackend.py:32: UserWarning: Numba cannot be loaded. You will gain possibly massive speed if installing it by \n",
      "\tc:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\python.exe -m pip install numba\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import grid2op\n",
    "from grid2op.PlotGrid import PlotMatplot\n",
    "from lightsim2grid import LightSimBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\github_clone\\\\L2RPN-rte-5'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\grid2op\\MakeEnv\\Make.py:438: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n"
     ]
    }
   ],
   "source": [
    "env_name = \"rte_case5_example\"  # or any other name.\n",
    "env = grid2op.make(env_name, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_ITERATION = 10\n",
    "EVAL_EPISODE = 1\n",
    "MAX_EVAL_STEPS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\grid2op\\MakeEnv\\Make.py:438: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n"
     ]
    }
   ],
   "source": [
    "from grid2op.gym_compat import GymEnv\n",
    "import grid2op\n",
    "from gymnasium import Env\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "try:\n",
    "    from lightsim2grid import LightSimBackend\n",
    "    bk_cls = LightSimBackend\n",
    "except ImportError as exc:\n",
    "    print(f\"Error: {exc} when importing faster LightSimBackend\")\n",
    "    from grid2op.Backend import PandaPowerBackend\n",
    "    bk_cls = PandaPowerBackend\n",
    "    \n",
    "env_name = \"rte_case5_example\"\n",
    "training_env = grid2op.make(env_name, test=True)  # we put \"test=True\" in this notebook because...\n",
    "# it's a notebook to explain things. Of course, do not put \"test=True\" if you really want\n",
    "# to train an agent...\n",
    "gym_env = GymEnv(training_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict('change_bus': MultiBinary(21), 'change_line_status': MultiBinary(8), 'set_bus': Box(-1, 2, (21,), int32), 'set_line_status': Box(-1, 1, (8,), int32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym_env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(166)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from grid2op.gym_compat import DiscreteActSpace\n",
    "gym_env.action_space = DiscreteActSpace(training_env.action_space)\n",
    "gym_env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('a_ex',\n",
       "              array([7.1869745e+02, 4.3956577e+02, 4.5736687e+01, 5.6552578e+01,\n",
       "                     4.5497098e+02, 5.4125762e-12, 5.4125762e-12, 8.9389944e+00],\n",
       "                    dtype=float32)),\n",
       "             ('a_or',\n",
       "              array([703.2866   , 422.33826  ,  39.433754 ,  51.658306 , 462.6719   ,\n",
       "                       7.7699723,   7.7699723,   9.35489  ], dtype=float32)),\n",
       "             ('actual_dispatch', array([0., 0.], dtype=float32)),\n",
       "             ('attention_budget', array([0.], dtype=float32)),\n",
       "             ('current_step', array([1])),\n",
       "             ('curtailment', array([0., 0.], dtype=float32)),\n",
       "             ('curtailment_limit', array([1., 1.], dtype=float32)),\n",
       "             ('curtailment_limit_effective', array([1., 1.], dtype=float32)),\n",
       "             ('day', 6),\n",
       "             ('day_of_week', 6),\n",
       "             ('delta_time', array([5.], dtype=float32)),\n",
       "             ('duration_next_maintenance', array([0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('gen_margin_down', array([ 0., 10.], dtype=float32)),\n",
       "             ('gen_margin_up', array([0.       , 0.7545223], dtype=float32)),\n",
       "             ('gen_p', array([ 1.7     , 29.245478], dtype=float32)),\n",
       "             ('gen_p_before_curtail', array([1.7, 0. ], dtype=float32)),\n",
       "             ('gen_q', array([ 205.5007, -206.6517], dtype=float32)),\n",
       "             ('gen_theta', array([-1.791303,  0.      ], dtype=float32)),\n",
       "             ('gen_v', array([102., 102.], dtype=float32)),\n",
       "             ('hour_of_day', 0),\n",
       "             ('is_alarm_illegal', 0),\n",
       "             ('line_status',\n",
       "              array([ True,  True,  True,  True,  True,  True,  True,  True])),\n",
       "             ('load_p', array([8.7, 7.8, 8.1], dtype=float32)),\n",
       "             ('load_q', array([6.1, 5.5, 5.7], dtype=float32)),\n",
       "             ('load_theta',\n",
       "              array([-1.791303 , -1.765996 , -1.7650408], dtype=float32)),\n",
       "             ('load_v',\n",
       "              array([102.     , 101.74243, 101.76417], dtype=float32)),\n",
       "             ('max_step', array([2016])),\n",
       "             ('minute_of_hour', 5),\n",
       "             ('month', 1),\n",
       "             ('p_ex',\n",
       "              array([ 1.8050985e+01,  1.0383456e+01, -6.9445629e+00, -8.9556198e+00,\n",
       "                     -1.0383573e+01,  9.2995956e-13,  9.2995956e-13,  8.5561943e-01],\n",
       "                    dtype=float32)),\n",
       "             ('p_or',\n",
       "              array([-1.4156376e+01, -8.7844782e+00,  6.9630990e+00,  8.9777555e+00,\n",
       "                      1.1194492e+01,  5.8139325e-05,  5.8139325e-05, -8.5543746e-01],\n",
       "                    dtype=float32)),\n",
       "             ('q_ex',\n",
       "              array([-1.2568202e+02, -7.6956520e+01, -4.0907679e+00, -4.3769689e+00,\n",
       "                      7.9701813e+01,  2.2246419e-13,  2.2246419e-13, -1.3230307e+00],\n",
       "                    dtype=float32)),\n",
       "             ('q_or',\n",
       "              array([123.43998   ,  74.09524   ,   0.22485395,   1.6406205 ,\n",
       "                     -80.96968   ,  -1.3726463 ,  -1.3726463 ,  -1.4092321 ],\n",
       "                    dtype=float32)),\n",
       "             ('rho',\n",
       "              array([1.1721444 , 1.9197193 , 0.24646096, 0.3228644 , 0.77111983,\n",
       "                     0.02589991, 0.02589991, 0.05846806], dtype=float32)),\n",
       "             ('target_dispatch', array([0., 0.], dtype=float32)),\n",
       "             ('thermal_limit',\n",
       "              array([600., 220., 160., 160., 600., 300., 300., 160.], dtype=float32)),\n",
       "             ('theta_ex',\n",
       "              array([ 0.        , -0.57796395, -1.765996  , -1.7650408 , -0.57796395,\n",
       "                     -0.5828175 , -0.5828175 , -1.7650408 ], dtype=float32)),\n",
       "             ('theta_or',\n",
       "              array([-1.791303  , -1.791303  , -1.791303  , -1.791303  ,  0.        ,\n",
       "                     -0.57796395, -0.57796395, -1.765996  ], dtype=float32)),\n",
       "             ('time_before_cooldown_line', array([0, 0, 0, 0, 0, 0, 0, 0])),\n",
       "             ('time_before_cooldown_sub', array([0, 0, 0, 0, 0])),\n",
       "             ('time_next_maintenance',\n",
       "              array([-1, -1, -1, -1, -1, -1, -1, -1])),\n",
       "             ('time_since_last_alarm', array([-1])),\n",
       "             ('timestep_overflow', array([1, 1, 0, 0, 0, 0, 0, 0])),\n",
       "             ('topo_vect',\n",
       "              array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1])),\n",
       "             ('v_ex',\n",
       "              array([102.     , 101.99492, 101.74243, 101.76417, 101.99492, 101.99604,\n",
       "                     101.99604, 101.76417], dtype=float32)),\n",
       "             ('v_or',\n",
       "              array([102.     , 102.     , 102.     , 102.     , 102.     , 101.99492,\n",
       "                     101.99492, 101.74243], dtype=float32)),\n",
       "             ('was_alarm_used_after_game_over', 0),\n",
       "             ('year', 2019)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, reward, terminated, truncated, info = gym_env.step(53)  # perform action labeled 0\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:155: UserWarning: You have specified a mini-batch size of 8, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 2\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=2 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "nn_model = PPO(env=gym_env,\n",
    "               learning_rate=1e-3,\n",
    "               policy=\"MultiInputPolicy\",\n",
    "               policy_kwargs={\"net_arch\": [100, 100, 100]},\n",
    "               n_steps=2,\n",
    "               batch_size=8,\n",
    "               verbose=True,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2        |\n",
      "|    ep_rew_mean     | 4.5      |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2        |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.5        |\n",
      "|    ep_rew_mean          | 2.25       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 0          |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 4          |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09049064 |\n",
      "|    clip_fraction        | 0.5        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.11      |\n",
      "|    explained_variance   | -0.01      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 2.36       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.102     |\n",
      "|    value_loss           | 6.25       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.5        |\n",
      "|    ep_rew_mean          | 2.25       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 0          |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 6          |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10257378 |\n",
      "|    clip_fraction        | 0.5        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.11      |\n",
      "|    explained_variance   | -0.0509    |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 9.37       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0967    |\n",
      "|    value_loss           | 21.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.5        |\n",
      "|    ep_rew_mean          | 2.25       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1          |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 8          |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11912358 |\n",
      "|    clip_fraction        | 0.55       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.11      |\n",
      "|    explained_variance   | 0.0368     |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 30.9       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0998    |\n",
      "|    value_loss           | 81.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3          |\n",
      "|    ep_rew_mean          | 12         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1          |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 10         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12380022 |\n",
      "|    clip_fraction        | 0.55       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.1       |\n",
      "|    explained_variance   | -0.0111    |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 27.9       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.101     |\n",
      "|    value_loss           | 68.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2aff900be50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.learn(total_timesteps=LEARNING_ITERATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\grid2op\\MakeEnv\\Make.py:438: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('c:\\\\Users\\\\Ernest\\\\.conda\\\\envs\\\\l2rpn-test\\\\lib\\\\site-packages\\\\grid2op\\\\data\\\\rte_case5_example\\\\chronics\\\\00',\n",
       "  '00',\n",
       "  8.319282531738281,\n",
       "  3,\n",
       "  2016),\n",
       " ('c:\\\\Users\\\\Ernest\\\\.conda\\\\envs\\\\l2rpn-test\\\\lib\\\\site-packages\\\\grid2op\\\\data\\\\rte_case5_example\\\\chronics\\\\02',\n",
       "  '02',\n",
       "  0.0,\n",
       "  1,\n",
       "  2016),\n",
       " ('c:\\\\Users\\\\Ernest\\\\.conda\\\\envs\\\\l2rpn-test\\\\lib\\\\site-packages\\\\grid2op\\\\data\\\\rte_case5_example\\\\chronics\\\\04',\n",
       "  '04',\n",
       "  19.28192138671875,\n",
       "  6,\n",
       "  2016),\n",
       " ('c:\\\\Users\\\\Ernest\\\\.conda\\\\envs\\\\l2rpn-test\\\\lib\\\\site-packages\\\\grid2op\\\\data\\\\rte_case5_example\\\\chronics\\\\06',\n",
       "  '06',\n",
       "  20.38006591796875,\n",
       "  6,\n",
       "  2016),\n",
       " ('c:\\\\Users\\\\Ernest\\\\.conda\\\\envs\\\\l2rpn-test\\\\lib\\\\site-packages\\\\grid2op\\\\data\\\\rte_case5_example\\\\chronics\\\\08',\n",
       "  '08',\n",
       "  44.322593688964844,\n",
       "  7,\n",
       "  2016),\n",
       " ('c:\\\\Users\\\\Ernest\\\\.conda\\\\envs\\\\l2rpn-test\\\\lib\\\\site-packages\\\\grid2op\\\\data\\\\rte_case5_example\\\\chronics\\\\01',\n",
       "  '01',\n",
       "  39.95808792114258,\n",
       "  7,\n",
       "  2016),\n",
       " ('c:\\\\Users\\\\Ernest\\\\.conda\\\\envs\\\\l2rpn-test\\\\lib\\\\site-packages\\\\grid2op\\\\data\\\\rte_case5_example\\\\chronics\\\\03',\n",
       "  '03',\n",
       "  5.221673488616943,\n",
       "  2,\n",
       "  2016),\n",
       " ('c:\\\\Users\\\\Ernest\\\\.conda\\\\envs\\\\l2rpn-test\\\\lib\\\\site-packages\\\\grid2op\\\\data\\\\rte_case5_example\\\\chronics\\\\05',\n",
       "  '05',\n",
       "  48.57865905761719,\n",
       "  11,\n",
       "  2016),\n",
       " ('c:\\\\Users\\\\Ernest\\\\.conda\\\\envs\\\\l2rpn-test\\\\lib\\\\site-packages\\\\grid2op\\\\data\\\\rte_case5_example\\\\chronics\\\\07',\n",
       "  '07',\n",
       "  50.5987548828125,\n",
       "  9,\n",
       "  2016),\n",
       " ('c:\\\\Users\\\\Ernest\\\\.conda\\\\envs\\\\l2rpn-test\\\\lib\\\\site-packages\\\\grid2op\\\\data\\\\rte_case5_example\\\\chronics\\\\09',\n",
       "  '09',\n",
       "  35.08827209472656,\n",
       "  7,\n",
       "  2016)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import grid2op\n",
    "from grid2op.Runner import Runner\n",
    "from grid2op.Agent import RandomAgent\n",
    "env = grid2op.make(env_name, test=True)\n",
    "NB_EPISODE = 10  # assess the performance for 10 episodes, for example\n",
    "NB_CORE = 2  # do it on 2 cores, for example\n",
    "PATH_SAVE = \"agents_log\"  # and store the results in the \"agents_log\" folder\n",
    "runner = Runner(**env.get_params_for_runner(), agentClass=RandomAgent)\n",
    "runner.run(nb_episode=NB_EPISODE, nb_process=NB_CORE, path_save=PATH_SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2rpn-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
