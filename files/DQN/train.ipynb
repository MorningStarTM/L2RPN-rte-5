{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Network import QNetwork\n",
    "from Agent import Agent\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import grid2op\n",
    "from grid2op.PlotGrid import PlotMatplot\n",
    "from lightsim2grid import LightSimBackend\n",
    "from grid2op.Action import TopologySetAction\n",
    "from grid2op.gym_compat import DiscreteActSpace\n",
    "from grid2op.gym_compat import GymEnv\n",
    "import grid2op\n",
    "from gymnasium import Env\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "from Agent import Agent\n",
    "from utils import obs_to_vect\n",
    "from collections import deque, namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\grid2op\\MakeEnv\\Make.py:438: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n"
     ]
    }
   ],
   "source": [
    "env_name = \"rte_case5_example\"  # or any other name.\n",
    "env = grid2op.make(env_name, test=True, action_class=TopologySetAction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\grid2op\\MakeEnv\\Make.py:438: UserWarning: You are using a development environment. This environment is not intended for training agents. It might not be up to date and its primary use if for tests (hence the \"test=True\" you passed as argument). Use at your own risk.\n",
      "  warnings.warn(_MAKE_DEV_ENV_WARN)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from lightsim2grid import LightSimBackend\n",
    "    bk_cls = LightSimBackend\n",
    "except ImportError as exc:\n",
    "    print(f\"Error: {exc} when importing faster LightSimBackend\")\n",
    "    from grid2op.Backend import PandaPowerBackend\n",
    "    bk_cls = PandaPowerBackend\n",
    "    \n",
    "env_name = \"rte_case5_example\"\n",
    "training_env = grid2op.make(env_name, test=True)  # we put \"test=True\" in this notebook because...\n",
    "# it's a notebook to explain things. Of course, do not put \"test=True\" if you really want\n",
    "# to train an agent...\n",
    "gym_env = GymEnv(training_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_env.action_space = DiscreteActSpace(training_env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = {}\n",
    "HP['BUFFER_SIZE'] = int(1e5)\n",
    "HP['BATCH_SIZE'] = 64\n",
    "HP['GAMMA'] = 0.99\n",
    "HP['TAU'] = 1e-3\n",
    "HP['LR'] = 5e-4\n",
    "HP['UPDATE_EVERY'] = 4\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=211, action_size=166, seed=1000, HP=HP, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(n_epsiode=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    eps = eps_start\n",
    "    for i_episode in range(1, n_epsiode+1):\n",
    "        state, *_ = gym_env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(obs_to_vect(state))\n",
    "            next_state, reward, done, _, _ = gym_env.step(action)\n",
    "            agent.step(obs_to_vect(state), action, reward, obs_to_vect(next_state), done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            scores_window.append(score)\n",
    "            scores.append(score)\n",
    "            eps = max(eps_end, eps_decay*eps)\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "            if i_episode % 100 == 0:\n",
    "                print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "            if np.mean(scores_window)>=200.0:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "                torch.save(agent.qnet_local.state_dict(), 'checkpoint.pth')\n",
    "                break\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 201.63\n",
      "Environment solved in -99 episodes!\tAverage Score: 201.63\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Agent' object has no attribute 'qnetwork_local'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mdqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 25\u001b[0m, in \u001b[0;36mdqn\u001b[1;34m(n_epsiode, max_t, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(scores_window)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200.0\u001b[39m:\n\u001b[0;32m     24\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnvironment solved in \u001b[39m\u001b[38;5;132;01m{:d}\u001b[39;00m\u001b[38;5;124m episodes!\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mAverage Score: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i_episode\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(scores_window)))\n\u001b[1;32m---> 25\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqnetwork_local\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Agent' object has no attribute 'qnetwork_local'"
     ]
    }
   ],
   "source": [
    "scores = dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2rpn-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
